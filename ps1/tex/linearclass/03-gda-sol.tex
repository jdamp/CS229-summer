\begin{answer}    
Using Bayes we can write:
\begin{align*}
&p(y=1 \mid x;\phi,\mu_0,\mu_1,\Sigma) = \frac{p(x\mid y=1; \mu_1, \Sigma)\cdot p(y=1;\phi) } {p(x;\phi,\mu_0,\mu_1,\Sigma)} \\
&= \frac{p(x\mid y=1; \mu_1, \Sigma)\cdot p(y;\phi) } {p(x \mid y=0;\phi,\mu_0,\mu_1,\Sigma)\cdot p(y=0;\phi) + p(x \mid y=1;\phi,\mu_0,\mu_1,\Sigma)\cdot p(y=1;\phi)} \\
&= \frac{1}{1 + \frac{p(y=0;\phi)}{p(y=1;\phi)}\cdot \frac{p(x \mid y=0;\phi,\mu_0,\mu_1,\Sigma)}{p(x \mid y=1;\phi,\mu_0,\mu_1,\Sigma)}}   
\end{align*}
Inserting the definitions:
\begin{align*}
&p(y=1 \mid x;\phi,\mu_0,\mu_1,\Sigma) = \frac{1}{1+ \frac{1-\phi}{\phi} \cdot \exp\left(-\frac{1}{2}(x-\mu_{0})^T \Sigma^{-1} (x-\mu_{0}) + \frac{1}{2}(x-\mu_{1})^T \Sigma^{-1} (x-\mu_{1})\right)} \\
&= \frac{1}{1+ \exp\left(\log\left(\frac{1-\phi}{\phi}\right)-\frac{1}{2}(x-\mu_{0})^T \Sigma^{-1} (x-\mu_{0})+\frac{1}{2}(x-\mu_{1})^T \Sigma^{-1} (x-\mu_{1})\right)} \\
\end{align*}
Expand the second and third term in the denominator:
\begin{align*}
&-(x-\mu_{0})^T \Sigma^{-1} (x-\mu_{0})+(x-\mu_{1})^T \Sigma^{-1} (x-\mu_{1})  = \\
& -x^T\Sigma^{-1} x + x^T\Sigma^{-1}\mu_0 + \mu_0^T\Sigma^{-1} x - \mu_0^T\Sigma^{-1}\mu_0 + x^T\Sigma^{-1} x - x^T\Sigma^{-1}\mu_1 - \mu_1^T\Sigma^{-1} x + \mu_1^T\Sigma^{-1}\mu_1 \\
&= 2 (\mu_0^T\Sigma^{-1} - \mu_1^T\Sigma^{-1})x - \mu_0^T\Sigma^{-1}\mu_0  + - \mu_1^T\Sigma^{-1}\mu_1 \\
\end{align*}
Therefore, by chosing
\begin{align*}
    \theta &= -\Sigma^{-1} (\mu_0 - \mu_1) \\
    \theta_0 &= - \log\left(\frac{1-\phi}{\phi}\right) + \frac{1}{2}\left(\mu_0^T\Sigma^{-1}\mu_0   - \mu_1^T\Sigma^{-1}\mu_1\right)
\end{align*}
one can achieve the desired form of the posterior distribution.
\end{answer}
